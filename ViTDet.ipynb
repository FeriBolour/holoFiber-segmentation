{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b6397a8",
   "metadata": {},
   "source": [
    "# ViTDet: Exploring Plain Vision Transformer Backbones for Object Detection\n",
    "\n",
    "Yanghao Li, Hanzi Mao, Ross Girshick†, Kaiming He†\n",
    "\n",
    "[[`arXiv`](https://arxiv.org/abs/2203.16527)] [[`BibTeX`](#CitingViTDet)]\n",
    "\n",
    "For more information regarding this work please refer to the link below:\n",
    "https://github.com/facebookresearch/detectron2/tree/main/projects/ViTDet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0932db2",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a2de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e766c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [30, 15]\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import re\n",
    "\n",
    "import fiftyone as fo\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54855292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.model_zoo import get_config\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import LazyConfig, instantiate\n",
    "from detectron2.config import LazyCall as L\n",
    "from detectron2.engine import (\n",
    "    AMPTrainer,\n",
    "    SimpleTrainer,\n",
    "    default_argument_parser,\n",
    "    default_setup,\n",
    "    default_writers,\n",
    "    hooks,\n",
    "    launch,\n",
    ")\n",
    "from detectron2.engine.defaults import create_ddp_model\n",
    "from detectron2.evaluation import inference_on_dataset, print_csv_format\n",
    "from detectron2.utils import comm\n",
    "\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "import detectron2\n",
    "\n",
    "logger = logging.getLogger(\"detectron2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc2da1",
   "metadata": {},
   "source": [
    "# Custom Function for Preparing Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6901d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seg_cotton_dicts(Train_data_path, image_id = 1):\n",
    "    import io\n",
    "    import ast\n",
    "    dataset_list = []\n",
    "    subset_folders = os.listdir(Train_data_path)\n",
    "\n",
    "    for frames in subset_folders:\n",
    "        if '.png' in frames:\n",
    "            dict_holder = {}\n",
    "            file_name = os.path.join(Train_data_path, frames)\n",
    "            dict_holder[\"file_name\"] = file_name\n",
    "            dict_holder[\"height\"], dict_holder[\"width\"] = cv2.imread(file_name).shape[0:2]\n",
    "            dict_holder[\"image_id\"] = image_id\n",
    "            dict_holder[\"fr_name\"] = re.sub(r'\\.png','',frames)\n",
    "            #s = open(file_name[0:-4] + '.txt').read().replace(':','')\n",
    "            annotations = []\n",
    "            with open(file_name[0:-4] + '.txt') as folder:\n",
    "                for (k,line) in enumerate(folder):\n",
    "                    tmp = line.split('[')\n",
    "                    segment = [ast.literal_eval('['+tmp[1])] # format = [[float]]\n",
    "                    cat_n_bbox = tmp[0].split()\n",
    "                    category = int(cat_n_bbox[0].replace(':', ''))\n",
    "                    bbox = [float(cat_n_bbox[1]), float(cat_n_bbox[2]), float(cat_n_bbox[3]), float(cat_n_bbox[4])]\n",
    "                    # dict_store has boxmode(0) = [x1,y1,x2,y2] not boxmode(1) = [x1,y1,w,h] as previous code (use code cautiously)\n",
    "                    dict_annot = {\n",
    "                        \"bbox\": bbox,\n",
    "                        \"bbox_mode\": detectron2.structures.BoxMode(0),\n",
    "                        \"category_id\": category,\n",
    "                        \"segmentation\": segment\n",
    "                    }\n",
    "                    annotations.append(dict_annot)\n",
    "\n",
    "                    \n",
    "\n",
    "            dict_holder[\"annotations\"] = annotations\n",
    "            #bboxes = np.loadtxt(io.StringIO(s), usecols=(4,))\n",
    "            \n",
    "            if 'train' in Train_data_path:\n",
    "                dataset_list.append(dict_holder)\n",
    "                image_id += 1\n",
    "            # what about the augmented images --> it does not append augmented images with this code? (else is valid for validation and test data)\n",
    "            else:\n",
    "                if 'aug' not in frames:\n",
    "                    dataset_list.append(dict_holder)\n",
    "                    image_id += 1\n",
    "    \n",
    "    return dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data_path = 'train_average'\n",
    "Base_path = 'Cotton Fiber Project'\n",
    "train_dataset_dicts = make_seg_cotton_dicts(Train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66928128",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"train_average\"]: #,,\"val\",\"test\" (enter inside list for val data creation)\n",
    "    DatasetCatalog.register(\"CFH_\" + d,lambda d=d: make_seg_cotton_dicts(os.path.join(Base_path,d)))\n",
    "    MetadataCatalog.get(\"CFH_\" + d).thing_classes=[\"fiber\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef51e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_train = MetadataCatalog.get(\"CFH_train_average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a99ae4f",
   "metadata": {},
   "source": [
    "If Training Set's COCO format already exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d2b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"CFH_train_average\", {}, \"CFH_train_average.json\", \"train_average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a7d4e",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test(cfg, model):\n",
    "    if \"evaluator\" in cfg.dataloader:\n",
    "        ret = inference_on_dataset(\n",
    "            model, instantiate(cfg.dataloader.test), instantiate(cfg.dataloader.evaluator)\n",
    "        )\n",
    "        print_csv_format(ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train(cfg):\n",
    "    model = instantiate(cfg.model)\n",
    "    logger = logging.getLogger(\"detectron2\")\n",
    "    logger.info(\"Model:\\n{}\".format(model))\n",
    "    model.to(cfg.train.device)\n",
    "\n",
    "    cfg.optimizer.params.model = model\n",
    "    optim = instantiate(cfg.optimizer)\n",
    "\n",
    "    train_loader = instantiate(cfg.dataloader.train)\n",
    "\n",
    "    model = create_ddp_model(model, **cfg.train.ddp)\n",
    "    trainer = (AMPTrainer if cfg.train.amp.enabled else SimpleTrainer)(model, train_loader, optim)\n",
    "    checkpointer = DetectionCheckpointer(\n",
    "        model,\n",
    "        cfg.train.output_dir,\n",
    "        trainer=trainer,\n",
    "    )\n",
    "    trainer.register_hooks(\n",
    "        [\n",
    "            hooks.IterationTimer(),\n",
    "            hooks.LRScheduler(scheduler=instantiate(cfg.lr_multiplier)),\n",
    "            hooks.PeriodicCheckpointer(checkpointer, **cfg.train.checkpointer)\n",
    "            if comm.is_main_process()\n",
    "            else None,\n",
    "            hooks.EvalHook(cfg.train.eval_period, lambda: do_test(cfg, model)),\n",
    "            hooks.PeriodicWriter(\n",
    "                default_writers(cfg.train.output_dir, cfg.train.max_iter),\n",
    "                period=cfg.train.log_period,\n",
    "            )\n",
    "            if comm.is_main_process()\n",
    "            else None,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    checkpointer.resume_or_load(cfg.train.init_checkpoint, resume=False)\n",
    "    if False and checkpointer.has_checkpoint():\n",
    "        # The checkpoint stores the training iteration that just finished, thus we start\n",
    "        # at the next iteration\n",
    "        start_iter = trainer.iter + 1\n",
    "    else:\n",
    "        start_iter = 0\n",
    "    trainer.train(start_iter, cfg.train.max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58292fe6",
   "metadata": {},
   "source": [
    "## Function to Save the Detectron2 Config into Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ee4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfg2yaml(cfg):\n",
    "    \n",
    "    with open(cfg.train.output_dir + \"/Config.txt\", 'w') as file:\n",
    "        file.write(str(cfg))\n",
    "    \n",
    "    os.rename(cfg.train.output_dir + \"/Config.txt\", cfg.train.output_dir + \"/Config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbef2fc",
   "metadata": {},
   "source": [
    "## Setup VitDet with Detectron2's LazyConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"config_file\":\"detectron2/projects/ViTDet/configs/COCO/mask_rcnn_vitdet_b_100ep.py\",\n",
    "    \"eval_only\":\"False\"\n",
    "}\n",
    "\n",
    "cfg = LazyConfig.load(args[\"config_file\"])\n",
    "# cfg.model.backbone.bottom_up.stages = detectron2.modeling.ResNet.make_default_stages(depth=50, norm='BN', stride_in_1x1=True)\n",
    "# cfg.model.backbone.norm = \"BN\"\n",
    "# cfg.model.backbone.bottom_up.stem = detectron2.modeling.backbone.BasicStem(in_channels=3, norm='BN', out_channels=64)\n",
    "cfg.dataloader.train.dataset = L(detectron2.data.get_detection_dataset_dicts)(names='CFH_train_average')\n",
    "cfg.dataloader.test.dataset = L(detectron2.data.get_detection_dataset_dicts)(names='CFH_train_average')\n",
    "# cfg.train.max_iter=50000\n",
    "# cfg.train.eval_period = 5000\n",
    "cfg.train.output_dir='Output'\n",
    "cfg.model.roi_heads.num_classes = 1\n",
    "# cfg.model.proposal_generator.nms_thresh = 0.6\n",
    "# cfg.optimizer.lr=0.0005\n",
    "# cfg.lr_multiplier.scheduler.milestones = [40000, 45000]\n",
    "# cfg.lr_multiplier.scheduler.values = [1.0, 0.1, 0.01]\n",
    "# cfg.lr_multiplier.scheduler.num_updates = 20000\n",
    "cfg.dataloader.train.total_batch_size = 1\n",
    "cfg.dataloader.train.num_workers = 1\n",
    "cfg.dataloader.test.num_workers = 1\n",
    "# cfg.train.checkpointer.period = 2500\n",
    "# cfg = LazyConfig.apply_overrides(cfg, args[\"opts\"])\n",
    "os.makedirs(cfg.train.output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_setup(args, cfg)\n",
    "cfg2yaml(cfg)\n",
    "do_train(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9ed64",
   "metadata": {},
   "source": [
    "### Display Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [14, 7]\n",
    "def load_json_arr(json_path):\n",
    "    lines = []\n",
    "    with open(json_path, 'r') as f:\n",
    "        for line in f:\n",
    "            lines.append(json.loads(line))\n",
    "    return lines\n",
    "\n",
    "experiment_metrics = load_json_arr(cfg.train.output_dir + '/metrics.json')\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.semilogy(\n",
    "    [x['iteration'] for x in experiment_metrics if 'total_loss' in x], \n",
    "    [x['total_loss'] for x in experiment_metrics if 'total_loss' in x])\n",
    "plt.legend(['total_loss'], loc='upper left')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.savefig(cfg.train.output_dir +  '/Loss Curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857bb7f5",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f624138",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.train.init_checkpoint = cfg.train.output_dir + '/model_0169999.pth'\n",
    "cfg.model.roi_heads.box_predictor.test_score_thresh = 0.9\n",
    "model = instantiate(cfg.model)\n",
    "model.to(cfg.train.device)\n",
    "model = create_ddp_model(model)\n",
    "DetectionCheckpointer(model).load(cfg.train.init_checkpoint)\n",
    "\n",
    "ret = inference_on_dataset(\n",
    "            model, instantiate(cfg.dataloader.test), instantiate(cfg.dataloader.evaluator)\n",
    "        )\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66dd09",
   "metadata": {},
   "source": [
    "## Visualize Model Output and Performance Using FiftyOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83243df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.delete()\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    data_path= \"Cotton Fiber Project/train_average\",\n",
    "    labels_path='Cotton Fiber Project/CFH_train_average.json',\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    label_types=[\"detections\", \"segmentations\"],\n",
    "    label_field = \"ground_truth\",\n",
    "    #name=\"Model_2500_1024BatchSize_15LR\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "classes = [\"fiber\"]\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Add predictions to samples\n",
    "with fo.ProgressBar() as pb:\n",
    "    for sample in pb(dataset):\n",
    "        i = 1\n",
    "        # Load image\n",
    "        image = cv2.imread(sample.filepath)\n",
    "        im = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w , c = image.shape\n",
    "        temp = image.copy()\n",
    "        temp = np.moveaxis(temp, -1, 0)\n",
    "        image = torch.from_numpy(temp)\n",
    "        dict_input = {\n",
    "           \"image\": image,\n",
    "           'height': h,\n",
    "           'width': w,\n",
    "        }\n",
    "        # Perform inference\n",
    "        preds = model([dict_input])\n",
    "        preds = preds[0]\n",
    "        labels = preds[\"instances\"].pred_classes.cpu().detach().numpy()\n",
    "        scores = preds[\"instances\"].scores.cpu().detach().numpy()\n",
    "        masks = preds[\"instances\"].pred_masks.cpu().detach().numpy()\n",
    "        \n",
    "        # Convert detections to FiftyOne format\n",
    "        detections = []\n",
    "        segmentations = []\n",
    "        for label, score, seg in zip(labels, scores, masks):\n",
    "            \n",
    "            if score > 0.1:\n",
    "                segmentations.append(\n",
    "                    fo.Detection.from_mask(\n",
    "                        mask=seg,\n",
    "                        label=classes[label],\n",
    "                        confidence=score\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "        # Save predictions to dataset\n",
    "        sample[\"predictions\"] = fo.Detections(detections=segmentations)\n",
    "        sample.save()\n",
    "\n",
    "print(\"Finished adding predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804141cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predictions_view.evaluate_detections(\n",
    "    \"predictions\",\n",
    "    gt_field=\"ground_truth_segmentations\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    "    use_masks=True,\n",
    "    classes= classes,\n",
    "    iou=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c1a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1756d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf91d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataset GTseg\n",
    "dataset.export(\n",
    "    labels_path= cfg.train.output_dir + \"/GTsegmentation.json\",\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    label_field = \"ground_truth_segmentations\",\n",
    ")\n",
    "\n",
    "# Export the dataset predictions\n",
    "dataset.export(\n",
    "    labels_path= cfg.train.output_dir + \"/predictions.json\" ,\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    label_field = \"predictions\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
