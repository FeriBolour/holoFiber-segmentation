{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b6397a8",
   "metadata": {},
   "source": [
    "# TensorMask\n",
    "Xinlei Chen, Ross Girshick, Kaiming He, Piotr DollÃ¡r\n",
    "\n",
    "[[`arXiv`](https://arxiv.org/abs/1903.12174)] [[`BibTeX`](#CitingTensorMask)]\n",
    "\n",
    "For more information regarding this work please refer to the link below:\n",
    "https://github.com/facebookresearch/detectron2/tree/main/projects/TensorMask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0932db2",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a2de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e766c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [30, 15]\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import re\n",
    "\n",
    "import fiftyone as fo\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54855292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, hooks\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "logger = logging.getLogger(\"detectron2\")\n",
    "\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer, default_argument_parser, default_setup, launch\n",
    "from detectron2.evaluation import COCOEvaluator, verify_results\n",
    "\n",
    "from detectron2.evaluation import inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "from tensormask import add_tensormask_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc2da1",
   "metadata": {},
   "source": [
    "# Custom Function for Preparing Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6901d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seg_cotton_dicts(Train_data_path, image_id = 1):\n",
    "    import io\n",
    "    import ast\n",
    "    dataset_list = []\n",
    "    subset_folders = os.listdir(Train_data_path)\n",
    "\n",
    "    for frames in subset_folders:\n",
    "        if '.png' in frames:\n",
    "            dict_holder = {}\n",
    "            file_name = os.path.join(Train_data_path, frames)\n",
    "            dict_holder[\"file_name\"] = file_name\n",
    "            dict_holder[\"height\"], dict_holder[\"width\"] = cv2.imread(file_name).shape[0:2]\n",
    "            dict_holder[\"image_id\"] = image_id\n",
    "            dict_holder[\"fr_name\"] = re.sub(r'\\.png','',frames)\n",
    "            #s = open(file_name[0:-4] + '.txt').read().replace(':','')\n",
    "            annotations = []\n",
    "            with open(file_name[0:-4] + '.txt') as folder:\n",
    "                for (k,line) in enumerate(folder):\n",
    "                    tmp = line.split('[')\n",
    "                    segment = [ast.literal_eval('['+tmp[1])] # format = [[float]]\n",
    "                    cat_n_bbox = tmp[0].split()\n",
    "                    category = int(cat_n_bbox[0].replace(':', ''))\n",
    "                    bbox = [float(cat_n_bbox[1]), float(cat_n_bbox[2]), float(cat_n_bbox[3]), float(cat_n_bbox[4])]\n",
    "                    # dict_store has boxmode(0) = [x1,y1,x2,y2] not boxmode(1) = [x1,y1,w,h] as previous code (use code cautiously)\n",
    "                    dict_annot = {\n",
    "                        \"bbox\": bbox,\n",
    "                        \"bbox_mode\": detectron2.structures.BoxMode(0),\n",
    "                        \"category_id\": category,\n",
    "                        \"segmentation\": segment\n",
    "                    }\n",
    "                    annotations.append(dict_annot)\n",
    "\n",
    "                    \n",
    "\n",
    "            dict_holder[\"annotations\"] = annotations\n",
    "            #bboxes = np.loadtxt(io.StringIO(s), usecols=(4,))\n",
    "            \n",
    "            if 'train' in Train_data_path:\n",
    "                dataset_list.append(dict_holder)\n",
    "                image_id += 1\n",
    "            # what about the augmented images --> it does not append augmented images with this code? (else is valid for validation and test data)\n",
    "            else:\n",
    "                if 'aug' not in frames:\n",
    "                    dataset_list.append(dict_holder)\n",
    "                    image_id += 1\n",
    "    \n",
    "    return dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data_path = 'train_average'\n",
    "Base_path = 'Cotton Fiber Project'\n",
    "train_dataset_dicts = make_seg_cotton_dicts(Train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66928128",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"train_average\"]: #,,\"val\",\"test\" (enter inside list for val data creation)\n",
    "    DatasetCatalog.register(\"CFH_\" + d,lambda d=d: make_seg_cotton_dicts(os.path.join(Base_path,d)))\n",
    "    MetadataCatalog.get(\"CFH_\" + d).thing_classes=[\"fiber\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef51e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_train = MetadataCatalog.get(\"CFH_train_average\")\n",
    "metadata_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a99ae4f",
   "metadata": {},
   "source": [
    "If Training Set's COCO format already exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d2b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"CFH_train_average\", {}, \"CFH_train_average.json\", \"train_average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a7d4e",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58292fe6",
   "metadata": {},
   "source": [
    "## Function to Save the Detectron2 Config into Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ee4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfg2yaml(cfg):\n",
    "    \n",
    "    with open(cfg.train.output_dir + \"/Config.txt\", 'w') as file:\n",
    "        file.write(str(cfg))\n",
    "    \n",
    "    os.rename(cfg.train.output_dir + \"/Config.txt\", cfg.train.output_dir + \"/Config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, output_dir=output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbef2fc",
   "metadata": {},
   "source": [
    "## Setup Detectron2's Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"config_file\":\"projects/TensorMask/configs/tensormask_R_50_FPN_6x.yaml\"\n",
    "}\n",
    "\"\"\"\n",
    "Create configs and perform basic setups.\n",
    "\"\"\"\n",
    "cfg = get_cfg()\n",
    "add_tensormask_config(cfg)\n",
    "cfg.merge_from_file(args[\"config_file\"])\n",
    "cfg.DATASETS.TRAIN = (\"CFH_train_average\",)\n",
    "cfg.DATASETS.TEST = (\"CFH_train_average\",)\n",
    "cfg.SOLVER.BASE_LR = 0.001  # Learning Rate\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.SOLVER.MAX_ITER = 50000\n",
    "cfg.SOLVER.STEPS = (40000,45000)\n",
    "cfg.MODEL.TENSOR_MASK.NUM_CLASSES = 1\n",
    "cfg.OUTPUT_DIR = \"Output\"\n",
    "# cfg.merge_from_list(args.opts)\n",
    "cfg.freeze()\n",
    "default_setup(cfg, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg2yaml(cfg)\n",
    "trainer = Trainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9ed64",
   "metadata": {},
   "source": [
    "### Display Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [14, 7]\n",
    "def load_json_arr(json_path):\n",
    "    lines = []\n",
    "    with open(json_path, 'r') as f:\n",
    "        for line in f:\n",
    "            lines.append(json.loads(line))\n",
    "    return lines\n",
    "\n",
    "experiment_metrics = load_json_arr(cfg.OUTPUT_DIR + '/metrics.json')\n",
    "\n",
    "# plt.legend(['training_loss', 'validation_loss'], loc='upper left')\n",
    "plt.legend(['training_loss'])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.savefig(cfg.OUTPUT_DIR +  '/Loss Curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857bb7f5",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f624138",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "add_tensormask_config(cfg)\n",
    "cfg.merge_from_file(args[\"config_file\"])\n",
    "cfg.DATASETS.TRAIN = (\"CFH_train_average\",)\n",
    "cfg.DATASETS.TEST = (\"CFH_train_average\",)\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.MODEL.TENSOR_MASK.NUM_CLASSES = 1\n",
    "cfg.OUTPUT_DIR = \"Output\"\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.TENSOR_MASK.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "# cfg.merge_from_list(args.opts)\n",
    "cfg.freeze()\n",
    "default_setup(cfg, args)\n",
    "\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f3840",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = COCOEvaluator(\"CFH_train_average\", output_dir=cfg.OUTPUT_DIR,use_fast_impl=False)\n",
    "val_loader = build_detection_test_loader(cfg, \"CFH_train_average\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66dd09",
   "metadata": {},
   "source": [
    "## Visualize Model Output and Performance Using FiftyOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83243df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.delete()\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    data_path= \"Cotton Fiber Project/train_average\",\n",
    "    labels_path='Cotton Fiber Project/CFH_train_average.json',\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    label_types=[\"detections\", \"segmentations\"],\n",
    "    label_field = \"ground_truth\",\n",
    "    #name=\"Model_2500_1024BatchSize_15LR\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "classes = [\"fiber\"]\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Add predictions to samples\n",
    "with fo.ProgressBar() as pb:\n",
    "    for sample in pb(dataset):\n",
    "        # Load image\n",
    "        image = cv2.imread(sample.filepath)\n",
    "        im = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w , c = image.shape\n",
    "\n",
    "        # Perform inference\n",
    "        preds = predictor(image)\n",
    "        if len(preds[\"instances\"]) != 0:\n",
    "            labels = preds[\"instances\"].pred_classes.cpu().detach().numpy()\n",
    "            scores = preds[\"instances\"].scores.cpu().detach().numpy()\n",
    "            masks = preds[\"instances\"].pred_masks.cpu().detach().numpy()\n",
    "\n",
    "            # Convert detections to FiftyOne format\n",
    "            detections = []\n",
    "            segmentations = []\n",
    "            for label, score, seg in zip(labels, scores, masks):\n",
    "\n",
    "                segmentations.append(\n",
    "                    fo.Detection.from_mask(\n",
    "                        mask=seg,\n",
    "                        label=classes[label],\n",
    "                        confidence=score\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # Save predictions to dataset\n",
    "            sample[\"predictions\"] = fo.Detections(detections=segmentations)\n",
    "            sample.save()\n",
    "\n",
    "print(\"Finished adding predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804141cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predictions_view.evaluate_detections(\n",
    "    \"predictions\",\n",
    "    gt_field=\"ground_truth_segmentations\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    "    use_masks=True,\n",
    "    classes= classes,\n",
    "    iou=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c1a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1756d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf91d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataset GTseg\n",
    "dataset.export(\n",
    "    labels_path= cfg.train.output_dir + \"/GTsegmentation.json\",\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    label_field = \"ground_truth_segmentations\",\n",
    ")\n",
    "\n",
    "# Export the dataset predictions\n",
    "dataset.export(\n",
    "    labels_path= cfg.train.output_dir + \"/predictions.json\" ,\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    label_field = \"predictions\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
