{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6666945",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554be14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "import contextlib\n",
    "import datetime\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import copy,torch,torchvision\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as X\n",
    "import math\n",
    "from itertools import repeat\n",
    "import re\n",
    "import shutil\n",
    "import io\n",
    "import ast\n",
    "\n",
    "from fvcore.common.file_io import PathManager\n",
    "from fvcore.common.timer import Timer\n",
    "\n",
    "from detectron2.structures import Boxes, BoxMode, PolygonMasks\n",
    "from detectron2.config import *\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.evaluation import RotatedCOCOEvaluator,DatasetEvaluators, inference_on_dataset, coco_evaluation,DatasetEvaluator\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from platform import python_version\n",
    "\n",
    "import glob\n",
    "import time\n",
    "import shutil\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import concurrent.futures\n",
    "\n",
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "from torch.utils.cpp_extension import CUDA_HOME\n",
    "print(torch.cuda.is_available(), CUDA_HOME)\n",
    "\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ad9fb",
   "metadata": {},
   "source": [
    "# Custom Function for Preparing Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rbbox(mask):\n",
    "    import cv2\n",
    "    cnts, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rbbox = cv2.minAreaRect(cnts[0])\n",
    "    return rbbox\n",
    "\n",
    "\n",
    "\n",
    "def make_rbbox_cotton_dicts(Train_data_path, image_id = 1):\n",
    "\n",
    "    padded_seg_dicts = make_seg_cotton_dicts(Train_data_path)\n",
    "\n",
    "    dataset_list = []\n",
    "    for file in padded_seg_dicts:\n",
    "\n",
    "        img_height = file['height']\n",
    "        img_width = file['width']\n",
    "        img_path = file['file_name']\n",
    "        frame_name = file['fr_name']\n",
    "\n",
    "        dict_holder = {}\n",
    "        dict_holder[\"file_name\"] = img_path\n",
    "        dict_holder[\"height\"] =  img_height\n",
    "        dict_holder[\"width\"] = img_width\n",
    "        dict_holder[\"image_id\"] = image_id\n",
    "        dict_holder[\"fr_name\"] = frame_name\n",
    "\n",
    "        # loop over each instance in current image and save annotations dictionary in a list\n",
    "        annotations = []\n",
    "        for index,variable in enumerate(file['annotations']):\n",
    "            category = variable['category_id']\n",
    "            segment = variable['segmentation']\n",
    "            mymask = detectron2.structures.polygons_to_bitmask(segment, img_height,img_width)\n",
    "            mymask = 255*mymask\n",
    "            rbbox = get_rbbox((mymask).astype('uint8'))\n",
    "            cent_x = rbbox[0][0]\n",
    "            cent_y = rbbox[0][1]\n",
    "            w = rbbox[1][0]\n",
    "            h = rbbox[1][1]\n",
    "            angle = rbbox[2]\n",
    "#             if h > w:\n",
    "#                 angle = 90-angle\n",
    "#             else:\n",
    "            angle = -angle # -angle works best (for now)\n",
    "            bbox = [cent_x, cent_y, w, h, angle]\n",
    "            bbox_mode = detectron2.structures.BoxMode(4) # box_mode = 4 --> (x_cent,y_cent,w,h,a)\n",
    "            dict_annot = {\n",
    "                            \"bbox\": bbox,\n",
    "                            \"bbox_mode\": bbox_mode,\n",
    "                            \"category_id\": category,\n",
    "                        }\n",
    "            annotations.append(dict_annot)\n",
    "\n",
    "        dict_holder[\"annotations\"] = annotations\n",
    "\n",
    "        if 'train' in Train_data_path:\n",
    "                    dataset_list.append(dict_holder)\n",
    "                    image_id += 1\n",
    "        else:\n",
    "            if 'aug' in frame_name:\n",
    "                dataset_list.append(dict_holder)\n",
    "                image_id += 1\n",
    "                \n",
    "    return dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data_path = 'train_average'\n",
    "Base_path = 'Cotton Fiber Project'\n",
    "rbbox_train_dicts = make_rbbox_cotton_dicts(Train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"train_average\"]: #,,\"val\",\"test\" (enter inside list for val data creation)\n",
    "    DatasetCatalog.register(\"CFH_\" + d,lambda d=d: make_seg_cotton_dicts(os.path.join(Base_path,d)))\n",
    "    MetadataCatalog.get(\"CFH_\" + d).thing_classes=[\"fiber\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_train = MetadataCatalog.get(\"CFH_train_average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d75d90",
   "metadata": {},
   "source": [
    "# Custom Dataset Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f2d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_transform_instance_annotations(annotation, transforms, image_size, *, keypoint_hflip_indices=None):\n",
    "    if annotation[\"bbox_mode\"] == BoxMode.XYWHA_ABS:\n",
    "        annotation[\"bbox\"] = transforms.apply_rotated_box(np.asarray([annotation[\"bbox\"]]))[0]\n",
    "    else:\n",
    "        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n",
    "        # Note that bbox is 1d (per-instance bounding box)\n",
    "        annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n",
    "        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n",
    "\n",
    "    return annotation\n",
    "\n",
    "def mapper(dataset_dict):\n",
    "    # Implement a mapper, similar to the default DatasetMapper, but with our own customizations\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "    image, transforms = T.apply_transform_gens([T.Resize((800, 800))], image)\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "    annos = [\n",
    "      my_transform_instance_annotations(obj, transforms, image.shape[:2]) \n",
    "      for obj in dataset_dict.pop(\"annotations\")\n",
    "      if obj.get(\"iscrowd\", 0) == 0\n",
    "    ]\n",
    "    instances = utils.annotations_to_instances_rotated(annos, image.shape[:2])\n",
    "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d94a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
